{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Habitat Suitability - Project on the Aspen Tree\n",
    "# (*Populus tremuloides*) in Colorado\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://plants.sc.egov.usda.gov/ImageLibrary/standard/jusc2_001_svp.jpg\"\n",
    "        alt=\"Rocky Mountain Juniper, courtesy of EHerman, D.E., et al. Provided by \n",
    "        ND State Soil Conservation Committee. United States, North Dakota)\" \n",
    "        height=\"400px\"/>\n",
    "    <img\n",
    "        src=\"https://plants.sc.egov.usda.gov/ImageLibrary/standard/jusc2_002_shp.jpg\"\n",
    "        alt=\"Rocky Mountain Juniper close up, courtesy of Herman, D.E., et al. \n",
    "        Provided by ND State Soil Conservation Committee. United States, North Dakota)\" \n",
    "        height=\"400px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Rocky Mountain Juniper, courtesy of Herman, D.E., et al.\n",
    "        (<span \n",
    "            class=\"citation\">\n",
    "            Herman, D.E., et al. Provided by ND State Soil Conservation Committee. \n",
    "            United States, North Dakota\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Description**\n",
    "\n",
    "Create a habitat suitability model for \n",
    "[*Juniperus scopulorum* Sargent](https://plants.usda.gov/DocumentLibrary/factsheet/pdf/fs_jusc2.pdf), \n",
    "a tree native to the Rocky Mounatin Region of North America. This habitat suitability \n",
    "model will focus on creating a modular, reproducible workflow. While climate change \n",
    "has changed or taken away suitable habitats for some plant species, the Rocky Mountain Juniper \n",
    "has remained stable and is even expaning habitat areas eastward (Hanberry 2022). However, \n",
    "this is at the expense of other ecosystems. Some climate change scenarios \n",
    "predict up to 90% loss of suitable habitats native grass species like *Sorghastrum nutans* \n",
    "(Kane et al. 2017). So, when thinking about grassland restoration, the \n",
    "effects of climate change and expanding species like *Juniperus scopulorum* \n",
    "Sargent must be taken into consideration for long-term viability of \n",
    "other plant species and ecosystems. This project will choose two study areas - National \n",
    "Grasslands, one in southern Colorado - Comanche National Grassland, and one in \n",
    "Nothern Colorado - Pawnee National Grassland. Both of these National Grasslands are \n",
    "in the Eastern Plains of Colorado which are to the east of the Rocky Mountains. The \n",
    "model used will be based on combining multiple data layers related to soil, topography, \n",
    "and climate (as raster layers) within the study area envelope (the two grasslands chosen).\n",
    "\n",
    "\n",
    "One variable related to soil is chosen ([from POLARIS dataset](http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/)):\n",
    "\n",
    "* pH (soil pH in H2O)\n",
    "\n",
    "\n",
    "Elevation from the SRTM:\n",
    "\n",
    "* Slope\n",
    "\n",
    "\n",
    "16 climate scenarios are chosen from the climate models on:\n",
    "(precipitation, monthly; and temperature minimum) these are described \n",
    "further in the methods section.\n",
    "\n",
    "\n",
    "### Citations\n",
    "\n",
    "* Hanberry, Brice B. 2022. “Westward Expansion by Juniperus Virginiana \n",
    "of the Eastern United States and Intersection with Western Juniperus \n",
    "Species in a Novel Assemblage.” Forests 13 (1): 101. \n",
    "https://doi.org/10.3390/f13010101.\n",
    "\n",
    "* Kane K, Debinski DM, Anderson C, Scasta JD, Engle DM and Miller JR. 2017.  \"Using Regional \n",
    "Climate Projections to Guide Grassland Community Restoration in the Face of Climate Change.\" \n",
    "Front. Plant Sci. 8:730. \n",
    "[doi: 10.3389/fpls.2017.00730](https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2017.00730/full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plant Species Description**\n",
    "\n",
    "*Juniperus scopulorum* Sargent, also known as Rocky Mountain Juniper \n",
    "Tree, is a coniferous tree that slowly grows to about 20 feet at 20 years \n",
    "but can grow up to 50 feet mature (U.S. Department of Agriculture - \n",
    "Natural Resources Conservation Service 2025). It also has a long life \n",
    "span with high drought tolerance which works to its favor in semi-airid \n",
    "climates like that of the Eastern Colorado Plains (U.S. Department of \n",
    "Agriculture -  Natural Resources Conservation Service 2025). It is native to \n",
    "North America throughout the Rocky Mountain region between British Colombia \n",
    "and Alberta, Canada all the way south through the continental U.S. to the \n",
    "four corner states and east through some of the Great Plains states \n",
    "(Stevens 2008). The Rocky Mountain juniper grows best below elevations \n",
    "of 7,500 feet, but typically between 5,000 and 7,500 feet (U.S. Department \n",
    "of Agriculture - Natural Resources Conservation Service 2002). While the \n",
    "Rocky Mountain juniper is frequently used as an ornamental tree or shrub \n",
    "tree in wildlife plantings and shelterbelts, it is also used by a range \n",
    "of birds and mammals for its ground cover or nesting materials (Stevens 2002). \n",
    "The Rocky Mountain junipers' berries also provide an important part of \n",
    "both bird and mammal diets (Stevens 2002). Additionaly, First Peoples have \n",
    "used this berries from this juniper for tea and other applications \n",
    "for medicinal purposes (Stevens 2008). Some potential problems or concerns \n",
    "about this tree/shrub tree are that it carries cedar-apple rust disease which \n",
    "is not harmful to itself but is harmful to other tree species (U.S. Department of \n",
    "Agriculture - Natural Resources Conservation Service 2002). Beyond diseases, \n",
    "the Rocky Mountain juniper increases are \"at the expense of other ecosystems, \n",
    "such as shrublands, grasslands, riparian forests, and open pine and oak \n",
    "forests, with consequent impacts on plant and wildlife species that flourish \n",
    "in open or unique ecosystems\" (Hanberry 2022).\n",
    "\n",
    "This species was chosen because of its prevelance in both the Pawnee National \n",
    "Grassland and the Comanche National Grassland. For the Pawnee National Grassland, \n",
    "the 'General Technical Report' from the USDA, Forest Service on *Vascular Plant* \n",
    "*Species of the Pawnee National Grassland* states that the *Juniperus scopulorum* \n",
    "Sargent occurs in the cliffs and ravines of this National Grassland (Hazlett \n",
    "1998). Similarly in the Comanche National Grassland, this same type of technical \n",
    "report states that *Juniperus scopulorum* Sargent occurs in all 3 counties \n",
    "(Baca, Otero, and Las Animas Counties) that this grassland is in, which also \n",
    "grow in \"shaded rocky canyons and ravines\" and \"Rocky: exposed limestone/shale \n",
    "barrens\" (Hazlett 2004). Because this species is expanding habitats, I am curious \n",
    "to see what the outcome of the habitat suitability model will be. \n",
    "This project could be done with any plant species of choice and could \n",
    "even be adapted to animal habitat suitability, but using other datasets \n",
    "and variables that would pertain to that species or locations of study areas chosen. \n",
    "\n",
    "Considering its growth conditions, *Juniperus scopulorum* Sargent has optimal \n",
    "pH values between 8.5 (max) and 5 (min), and annual precipitation between 26 \n",
    "inches and 9 inches (66cm - 23cm), and  (U.S. Department of Agriculture -  Natural \n",
    "Resources Conservation Service 2025). Root depths at a minimum are 9 inches (23cm) \n",
    "and the minimum temperature is -38 (°F) (U.S. Department of Agriculture -  Natural \n",
    "Resources Conservation Service 2025). While there are other factors that could be \n",
    "taken into consideration for growth, those are the two variables that will be \n",
    "chosen for this project. To look at other growth condition factors as well as \n",
    "additional information about *Juniperus scopulorum* Sargent, please visit \n",
    "[Natural Resources Conservation Service - USDA, Plant Profile Characteristics for *Juniperus scopulorum* Sarg.](https://plants.usda.gov/plant-profile/JUSC2/characteristics).\n",
    "\n",
    "\n",
    "### Citations\n",
    "\n",
    "* Hanberry, Brice B. 2022. “Westward Expansion by Juniperus Virginiana \n",
    "of the Eastern United States and Intersection with Western Juniperus \n",
    "Species in a Novel Assemblage.” Forests 13 (1): 101. \n",
    "https://doi.org/10.3390/f13010101.\n",
    "\n",
    "* Hazlett, Donald. 1998. “Vascular Plant Species of the Pawnee National \n",
    "Grassland.” U.S. Department of Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr017.pdf.\n",
    "\n",
    "* Hazlett, Donald L. 2004. “Vascular Plant Species of the Comanche \n",
    "National Grassland in Southeastern Colorado.” U.S. Department of \n",
    "Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr130.pdf.\n",
    "\n",
    "* Stevens, Michelle. 2002. “Plant Guide for Rocky Mountain Juniper \n",
    "(Juniperus Scopulorum Sarg.).” U.S. Department of Agriculture - Natural \n",
    "Resources Conservation Service. \n",
    "https://plants.usda.gov/DocumentLibrary/plantguide/pdf/cs_jusc2.pdf.\n",
    "\n",
    "* U.S. Department of Agriculture -  Natural Resources Conservation Service. 2025. \n",
    "“Plant Profile Characteristics of Juniperus Scopulorum Sarg. (Rocky Mountain \n",
    "Juniper).” Usda.gov. 2025. \n",
    "https://plants.usda.gov/plant-profile/JUSC2/characteristics.\n",
    "\n",
    "* U.S. Department of Agriculture - Natural Resources Conservation Service. 2002. \n",
    "“Plant Fact Sheet: ROCKY MOUNTAIN JUNIPER (Juniperus Scopulorum Sarg.).” \n",
    "U.S. Department of Agriculture, Natural Resources Conservation Service. \n",
    "https://plants.usda.gov/DocumentLibrary/factsheet/pdf/fs_jusc2.pdf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Site Descriptions**\n",
    "\n",
    ">**Land Acknowledgement**:\n",
    "First Peoples and Indigenous Peoples are the original stewards of the land taken before, \n",
    "during, and beyond colonialism in the Americas. Much of recorded history has prioritized \n",
    "Euro American perspectives and experiences that have misrepresented, excluded, and erased \n",
    "Black, Indigenous, and People of Color perspectives and experiences (History Colorado, \n",
    "Grounding Virtues). First People's and Indigenous People's stewardship and connection \n",
    "to this land must be honored and respected.\n",
    "\n",
    "*Please read the land acknowledgement above the map before continuing reading,* \n",
    "*it is imperative to naming and confronting racialized systems that dominate history*\n",
    "*and our current era.*\n",
    "\n",
    "Two study areas were chosen from the [U.S. National Grassland Units](https://data-usfs.hub.arcgis.com/datasets/usfs::national-grassland-units-feature-layer/explore?location=39.118879%2C-104.194688%2C7.05). \n",
    "Both of these grasslands are in Colorado, one in nothern Colorado and \n",
    "one in southern Colorado. I chose these two study areas specifically \n",
    "because I wanted to see if there was a difference between the northern \n",
    "grassland (Pawnee) and the southern grassland (Comanche) in terms of \n",
    "habitat suitability. A possible disadvantage to choosing two grasslands \n",
    "that are relatively close to one another is that the model outcomes showing \n",
    "a more suitable habitat in a certain study area, may not be noticeable. \n",
    "An advantage may be providing model outcomes within a singular unit of a state\n",
    "or Colorado Eastern Plains region, is providing insight for that area. \n",
    "\n",
    "The two grasslands are similar in that they are split geographically \n",
    "in two units or areas, however the Comanche is about twice the size of the Pawnee \n",
    "National Grassland.\n",
    "\n",
    "The research sources will show that the Rocky Mountain Juniper can be found \n",
    "in both National Grasslands chosen (Hazlett 1998 and 2004). So, I found it \n",
    "unecessary to try to do something like plotting GBIF occurances of the species; \n",
    "however, depening on the base of knowledge and, if you aren't sure if a certain \n",
    "species occurs in an area, it would be a great idea to plot GBIF occurences and \n",
    "see if they occur in the administrative boundaries chosen. \n",
    "\n",
    "* ### Comanche National Grassland\n",
    "![Comanche National Grassland, Vogel Canyon](https://www.colorado.com/_next/image?url=https%3A%2F%2Fapi.colorado.com%2Fsites%2Fdefault%2Ffiles%2F2024-10%2Fw_Vogel_Canyon_Comanche_Natl_Park2.jpg&w=3840&q=75 \"Vogel Canyon, Comanche National Grassland, courtesy of Colorado.com\")\n",
    "\n",
    "<embed>\n",
    "    <img\n",
    "        src=\"../img/map_of_comanche_national_grassland.png\"\n",
    "        alt=\" 'Map of the scattered 443,765 acres of Comanche National \n",
    "        Grassland (green) in southeastern Colorado. State land is blue and \n",
    "        Bureau of Land Management land is yellow. The northwestern Timpas \n",
    "        Unit is in Otero and Las Animas counties.The southeastern Carrizo Unit \n",
    "        is in Baca and Las Animas counties' courtesy of Donald L. Hazlett, 2004,\n",
    "        page 1)\" \n",
    "        height=\"700px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        \"Map of the scattered 443,765 acres of Comanche National \n",
    "        Grassland (green) in southeastern Colorado. State land is blue and \n",
    "        Bureau of Land Management land is yellow. The northwestern Timpas \n",
    "        Unit is in Otero and Las Animas counties.The southeastern Carrizo Unit \n",
    "        is in Baca and Las Animas counties\"\n",
    "        (<span \n",
    "            class=\"citation\">\n",
    "             Hazlett, 2004, page 1\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</embed>\n",
    "\n",
    "The Comanche National Grassland \"is named in honor of the Comanche tribe. \n",
    "The Comanche name is believed to be derived from Komontcia, a Ute word that\n",
    "means 'People Who Fight Us All the Time' (Pritzker 2000). This nickname, \n",
    "assigned by the Utes, reflects the Comanche reputation among other tribes \n",
    "and among pioneers as fierce fighters\" (Hazlett 2004, page 3). Between the \n",
    "18th and 19th centuries there were many 'claims' to this land where the \n",
    "Comanche National Grassland currently is situated by absentee ownership \n",
    "of the U.S., France, and Mexico, but by 1853 the Comanche were 'asked' \n",
    "(forced) to sign a 'treaty', which ceded any remaining lands that were \n",
    "not previously ceded (taken)(Hazlett 2004, pages 1-4). Thus the \n",
    "\"remaining Comanche groups in southeastern Colorado had lost their homeland \n",
    "and lifestyle\" (Hazlett 2004, page 3).\n",
    "\n",
    "After the Dust Bowl resulted in much abandoned farmland the \"National\n",
    "Industrial Act and Emergency Relief Appropriations Act that passed \n",
    "Congress in 1933 and 1935 gave the Federal government the authority \n",
    "to purchase failed crop lands\" (Worster 2004). It wasn't until 1954 \n",
    "that \"the administration of these lands was transferred to the \n",
    "USDA-Forest Service\" (Hazlett 2004, page 4). In 1960 the Comanche\n",
    "National Grassland was created to be managed by the USDA-Forest Service \n",
    "to conserve \"the natural resources of grass, water and wildlife habitat(s)\" \n",
    "and protect prehistoric and historic, cultural and natural assets \n",
    "(U.S. Department of Agriculture , U.S. Forest Service 2014). It consists \n",
    "of around 440,000 acres of discontinuous land that is located in the \n",
    "corner of southeastern Colorado (U.S. Department of Agriculture , U.S. \n",
    "Forest Service 2014). This grassland is situated between three different \n",
    "Colorado counties: Baca, Otero, and Las Animas and can be further identified \n",
    "as two distinct units the *Carrizo Unit* south and west of Springfield \n",
    "and the *Timpas Unit* south of La Junta\" (Hazlett 2004, page 4).\n",
    "\n",
    "The Comanche National Grassland is within what most plant geographers \n",
    "classify as the 'North American Prairie Province' (Hazlett 2004, page 5). \n",
    "Rockey Mountain junipers grow in 'rocky outcrops' which \"are areas within \n",
    "the open steppe, such as hilltops, where erosion has exposed a rocky surface \n",
    "or barren (Hazlett 2004, page 8 and 17). A “barren” is defined here, in \n",
    "a broad sense, as a sparsely vegetated exposed bedrock of shale, shale-derived \n",
    "soils, chalk, or limestone soils with microorganisms in a calcite matrix \n",
    "(Kelso et al. 2003). They also grow in the Comanche National Grassland in \n",
    "'shaded rock canyons and ravines' which are characterized as \"the steep, rugged \n",
    "relief areas that comprise the rocky cliffs, rock slicks, and shaded ledges \n",
    "in the major canyons... Included here are hills with large boulders \n",
    "and steep ridges... The greater water availability along cliff faces is \n",
    "complemented by less evaporation due to greater amounts of shade. This is a \n",
    "habitat of deep water percolation and occasional shade\" (Hazlett 2004, page \n",
    "8 and 17). Due to the vast expanse of land the Comanche National Grassland \n",
    "occupies (over 100 miles from one end to the other) the \"Annual rainfall amounts \n",
    "on the Comanche National Grassland have a high degree of spatial and temporal \n",
    "variation.\" (Hazlett 2004, pages 4-5). The closest weather center, Western \n",
    "Regional Climate Center (WRCC), reports a 55-year annual average as 11.5 inches \n",
    "; however, this climate center is 4 miles away from La Junta, which is north \n",
    "of Vogel Canyon (see map above, La Junta would be off the map to the north of \n",
    "Vogel Canyon) (Hazlett 2004, pages 4-5). So, that percipitation number would \n",
    "not be accurate or reflective of all of this National Grassland due to its size.\n",
    "\n",
    "The [*Vascular plant species of the Comanche National Grassland in southeastern Colorado*](https://www.fs.usda.gov/rm/pubs/rmrs_gtr130.pdf) \n",
    "by Donald Hazlett, 2004, was very comprehensive not only of vegetation, but also history, \n",
    "geology, and climate and should be read if interested in more in depth context \n",
    "information than can be provided there.\n",
    "\n",
    "* ### Pawnee National Grassland\n",
    "\n",
    "<embed>\n",
    "    <img\n",
    "        src=\"../img/pawnee_national_grassland_img.png\"\n",
    "        alt=\" Image of Pawnee National Grassland showing Rocky Mountain\n",
    "        Juniper Trees courtesy of Donald L. Hazlett, 1998)\" \n",
    "        height=\"650px\"/>\n",
    "            <figcaption aria-hidden=\"true\">\n",
    "             Image of Pawnee National Grassland showing Rocky Mountain\n",
    "             Juniper Trees - courtesy of Hazlett, Donald L. (1998).\n",
    "                (<span \n",
    "                 class=\"citation\">\n",
    "                 Hazlett 1998, page 'cover page'\n",
    "                </span>)\n",
    "            </figcaption>\n",
    "    <img\n",
    "        src=\"../img/map_of_pawnee_national_grassland.png\"\n",
    "        alt=\"Image of Pawnee National Grassland showing Rocky Mountain\n",
    "        Juniper Trees courtesy of Donald L. Hazlett, 1998)\" \n",
    "        height=\"500px\"/>\n",
    "            <figcaption aria-hidden=\"true\">\n",
    "             Map of Pawnee National Grassland.\n",
    "                (<span \n",
    "                 class=\"citation\">\n",
    "                 Hazlett 1998, page 2\n",
    "                </span>)\n",
    "            </figcaption>\n",
    "</embed>\n",
    "\n",
    "There is a lack of information available on this particular grassland as it \n",
    "relates to First Peoples, and most context information I am finding about the \n",
    "history of this grassland starts with settlers or pioneers 'settling' the land \n",
    "which feeds the Euro American perspective on history and excluding Indigenous \n",
    "perspectives and experiences of this land. What little information I did find \n",
    "was in someone's blog stating that \"these lands were the home of the Arapaho \n",
    "and Cheyenne, who were forcibly removed in the 1880s to allow white settlers \n",
    "to establish homesteads and farm the land\" (Diana 2021). However, there was \n",
    "no source given as to where this blogger found that information (Diana 2021). \n",
    "I acknowledge that much more research is needed for the historic and cultural \n",
    "context that does not start with pioneers. \n",
    "\n",
    "That being said, settlers in the mid 19th century used this land for \n",
    "cow grazing due to the aird nature of the land being difficult to grow \n",
    "crops (Rhoads n.d.). Later in the late 19th century through the early \n",
    "20th century there were waves of newcomers and continued use of land for \n",
    "grazing, but similar to the Comanche National Grassland the after effects \n",
    "of the Dust Bowl lead to the U.S. Forest Service mangaing the area in 1954 \n",
    "then getting permanent control in 1960 (Rhoads n.d.). The Pawnee National \n",
    "Grassland differs from the Comanche in that it has over 200 avtive oil and gas \n",
    "leases on the grassland that are managed by the Bureau of Land Management, and \n",
    "the U.S. Forest Service \"specifies the revegetation procedures to be followed \n",
    "by the private operators while conducting their exploration, drilling and \n",
    "production activities\" (Rhoads n.d.). This land is about 10% of the \n",
    "Pawnee National Grassland and is labeled (CPER - Central Plains Experimental \n",
    "Range) on the map above (Hazlett 1998, page 2). It should be noted that \n",
    "the data used for the study area -\n",
    "[U.S. National Grassland Units](https://data-usfs.hub.arcgis.com/datasets/usfs::national-grassland-units-feature-layer/explore?location=39.118879%2C-104.194688%2C7.05), \n",
    "include this private land and that should be kept in mind with any analyses.\n",
    "\n",
    "The Pawnee National Grassland consists of around 193,000 acres of discontinuous \n",
    "land (less than half the size of the Comanche National Grassland) that is \n",
    "located in northeastern Colorado, Weld County, on the border of Wyoming (Hazlett \n",
    "1998, pages 1-2). This grassland is within the Central Shortgrass Prairie \n",
    "Ecoregion and \"geomorphic sections of the Great Plains province known \n",
    "as the High Plains and the Colorado Piedmont (Trimble 1980)\" (Hazlett 1998, \n",
    "pages 3-4). Rocky Mountain junipers grow in similar areas in this grassland \n",
    "as they do in the Comanche National Grassland - in cliffs and ravines (Hazlett \n",
    "1998, page 7). The climate here is affected by \"continentality, air masses, \n",
    "and mountain barrier\" of the Rocky Mountains which block marine polar air masses \n",
    "from the west contributing to the drier conditions on the Great Plains (Hazlett \n",
    "1998, page 1). The 21-year average annual rainfall, measured between 1969-1989, \n",
    "was 12.6 inches which is similar to the annual average from the Comanche National \n",
    "Grassland (11.5 inches) (Hazlett 1998, page 1). However, this data is out of \n",
    "date considering the current increased impact of climate change.\n",
    "\n",
    "\n",
    "The [*Vascular plant species of the Pawnee National Grassland*](https://www.fs.usda.gov/rm/pubs/rmrs_gtr017.pdf) \n",
    "by Donald Hazlett, 1998, was also comprehensive not only of vegetation, but also  \n",
    "geology, soils, and climate and should be read if interested in more in depth \n",
    "context information than can be provided hhere. While this publication is missing \n",
    "the historic context related to the site, unlike his later report on the Comanche \n",
    "National Grassland, it is still very detailed and worth the read!\n",
    "\n",
    "### Citations\n",
    "\n",
    "* Diana. 2021. “Colorado Destinations: Pawnee National Grassland.” \n",
    "Handstands around the World. June 22, 2021. \n",
    "https://handstandsaroundtheworld.blog/2021/06/21/colorado-destinations-pawnee-national-grassland/.\n",
    "\n",
    "* Hazlett, Donald. 1998. “Vascular Plant Species of the Pawnee National \n",
    "Grassland.” U.S. Department of Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr017.pdf.\n",
    "\n",
    "* Hazlett, Donald L. 2004. “Vascular Plant Species of the Comanche \n",
    "National Grassland in Southeastern Colorado.” U.S. Department of \n",
    "Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr130.pdf.\n",
    "\n",
    "* History Colorado. n.d. “History Colorado Anti-Racism Work: Grounding \n",
    "Virtues | Goals | Accountability.” History Colorado. Accessed March 1, 2025. \n",
    "https://www.historycolorado.org/sites/default/files/media/document/2020/Anti-Racism_Grounding_Virtues.pdf.\n",
    "\n",
    "* Kelso, Sylvia, Nathan W Bower, Kirsten E Heckmann, Paul M Beardsley, \n",
    "and Darren G Greve. 2003. “GEOBOTANY of the NIOBRARA CHALK BARRENS in \n",
    "COLORADO: A STUDY of EDAPHIC ENDEMISM.” Western North American Naturalist \n",
    "63 (3): 299–313. https://doi.org/10.2307/41717298.\n",
    "\n",
    "* Pritzker, Barry. 2000. “A Native American Encyclopedia : History, \n",
    "Culture, and Peoples.” Internet Archive. Oxford ; New York : Oxford \n",
    "University Press. 2000. \n",
    "https://archive.org/details/nativeamericanen0000prit/page/n9/mode/2up.\n",
    "\n",
    "* Rhoads, Dorothy, and Lee Rhoads. n.d. “Arapaho & Roosevelt National \n",
    "Forests Pawnee National Grassland: Pawnee National Grassland History.” \n",
    "Usda.gov. U.S. Department of Agriculture, U.S. Forest Service. Accessed \n",
    "March 1, 2025. \n",
    "https://www.fs.usda.gov/detail/arp/learning/history-culture/?cid=fsm91_058308.\n",
    "\n",
    "* Trimble, Donald E. 1980. “GEOLOGICAL SURVEY BULLETIN 1493: The Geologic \n",
    "History of the Great Plains.” Washington: U.S. Department of the Interior, \n",
    "U.S. Geological Survey. https://pubs.usgs.gov/bul/1493/report.pdf.\n",
    "\n",
    "* U.S. Department of Agriculture , U.S. Forest Service. 2014. “Pike-San \n",
    "Isabel National Forests & Cimarron and Comanche National Grasslands - Comanche \n",
    "National Grassland.” Fs.usda.gov. U.S. Department of Agriculture , U.S. \n",
    "Forest Service. 2014. https://www.fs.usda.gov/recarea/psicc/recarea/?recid=12409.\n",
    "\n",
    "* Worster, Donald. 2004. Dust Bowl : The Southern Plains in the 1930s. \n",
    "25th Anniversary Edition. New York: Oxford University Press.\n",
    "(https://global.oup.com/ushe/product/dust-bowl-9780195174885?cc=us&lang=en&)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Descriptions**\n",
    "\n",
    "* ### Administrative Boundaries: USFS National Grassland Units (used for study sites)\n",
    "\n",
    "The [USFS (United States Forest Service) National Grassland Units](https://data-usfs.hub.arcgis.com/datasets/usfs::national-grassland-units-feature-layer/explore?location=39.118879%2C-104.194688%2C7.05) \n",
    "is a dataset of administrative boundaries of National Grasslands. \n",
    "This is just one feature layer that the USFS Geospatial Data Discovery \n",
    "website has to offer. There are many other types of data topics such as \n",
    "forest management, ecosystems, hydrology, and more that can be further \n",
    "explored.The USFS Grassland Units feature layer, like the other data \n",
    "available on this webpage, was created by the USFS, an authoritative \n",
    "source, to provide geospatial data published by the agency. This \n",
    "particular layer is used in this project in order to provide the study \n",
    "area boundaries. Specific grassland boundaries can be selected from the \n",
    "layer, for this project the Comanche and Pawnee National Grasslands \n",
    "will be selected. This data is downloaded as a shapefile and the \n",
    "boundaries of the national grasslands will provide the base for the other \n",
    "data in this project (raster layers) to be built upon. \n",
    "\n",
    "A disadvantage to using these boundaries are that the areas are \n",
    "typically discontinuous so it may potentially be difficult to \n",
    "visually see analyses on plots. Other shapfiles could also be used as \n",
    "boundaries like National Parks, Forests, or other defined units \n",
    "that match with the species chosen or goals of research.\n",
    "\n",
    "The USFS Grassland Units data was created in 2017 and says that it is \n",
    "updated weekly but the last update was in 2022; however, the boundaries \n",
    "or land associated with these in theory wouldn't be drastically changing \n",
    "on a weekly or even monthly basis. This data is publically accessible \n",
    "and can be used under a \n",
    "[CC0 1.0 License](https://creativecommons.org/publicdomain/zero/1.0/),\n",
    "which essentially means there is no copyright and permission is not \n",
    "needed to use it.\n",
    "\n",
    "* ### Soil Data: POLARIS soil properties database (variables related to soil)\n",
    "\n",
    "The POLARIS database for soil properties is a database of a century of \n",
    "soil survey data that is on a server hosted by Duke University. However, \n",
    "while part of the data collected comes from soil surveys, this dataset \n",
    "fills in unsruveyed areas with a series of probabilities for what the soil \n",
    "type in a specific area is. This filling in helps create a continuous layer to \n",
    "work with and makes it easier to work with choosing a study area where not every \n",
    "30m by 30m section was surveyed, and still able to use this data. For analysis \n",
    "it does need to be kept in mind that the filled areas may not be totally accurate, \n",
    "but they are a good estimate of what the soil type is. There are 13 soil property \n",
    "variables available, each with 5 statistics avaialble, at 6 different depth layers, \n",
    "then 1x1 degree tifs (Dr.Chaney). The README on this data set states an important \n",
    "notice about these tifs - \"Due to file size constraints, the 1 arcsec database \n",
    "is split into 1x1 degree tiffs. Each variable/layer/statistic has its own virtual \n",
    "raster that acts as the \"glue\" of all the smaller 1x1 degree chunks. For more \n",
    "information on virtual rasters see \n",
    "https://www.gdal.org/gdal_vrttut.html\" (POLARIS soil properties datbase). \n",
    "Besides the README there are helpful websites that give more information about this \n",
    "datset such as \n",
    "[POLARIS – a probabilistic soil classification and property database over the contiguous United States at a 30-meter spatial resolution](https://otc.duke.edu/technologies/polaris-a-probabilistic-soil-classification-and-property-database-over-the-contiguous-united-states-at-a-30-meter-spatial-resolution/#:~:text=The%20POLARIS%20soil%20series%20database,of%20the%20currently%20available%20database)\n",
    ", [Polaris 30m Probabilistic Soil Properties US](https://gee-community-catalog.org/projects/polaris/#data-characteristics),\n",
    "and [Chaney et al.](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018WR022797).\n",
    "\n",
    "An advantage of using this dataset is that it provides a \"spatially \n",
    "continuous, internally consistent, and quantitative prediction of soil \n",
    "classification and property database with a high degree of granularity \n",
    "(30-meter) covering the entire contiguous United States\" (Dr. Chaney).\n",
    "A disadvantage to this database would be that this is only for \n",
    "the contiguous United States (CONUS).\n",
    "\n",
    "For this particular project, two variables are chosen, pH and theta_s \n",
    "which is saturated soil water content, m3/m3. These two variables were \n",
    "chosen because optimal levels or measurements of both were found for the \n",
    "Rocky Mountain Juniper. These two variables will use the mean statistic \n",
    "available at the 60-100cm depth (this relates to root depth of the plant \n",
    "species chosen). Mean is one of the easier statistics given to work with \n",
    "which is why it was chosen. The 60-100cm depth was chosen because the \n",
    "minimum root depth for the Rocky Mountain Juniper is 51cm which does \n",
    "fall in the 30-60cm depth, however because 51cm is the minimum and would \n",
    "fall in the latter part of that depth range, the range above this was chosen.\n",
    "Make sure to pay atttention to the depth being used which depends on the \n",
    "root depth of the plant species chosen. This dataset is in 30m resolution \n",
    "which is needed in order to harmonize the rasters.\n",
    "\n",
    "This database is accessible and can be used under \n",
    "[Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/deed.en). \n",
    "The database can be accessed here - \n",
    "[POLARIS soil properties database](http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/)\n",
    "\n",
    "* ### Elevation Data: earthaccess API (elevation from the SRTM - used to calculate slope)\n",
    "\n",
    "Earthaccess \"is a python library to search for, and download or stream \n",
    "NASA Earth science data with just a few lines of code\" (earthaccess API \n",
    "(description in User Guide)). This library is made available by the \n",
    "National Snow and Ice Data Center (NSIDC), with many contributors to \n",
    "this specific repository which is publically accessible. Earthaccess \n",
    "is a great contribution to open science efforts making it easier to \n",
    "access and download NASA datasets by \"reducing barriers to cloud based \n",
    "analysis\" (earthaccess API (description in User Guide)). \n",
    "\n",
    "Earthaccess API (Application Programming Interface) is used in \n",
    "this project to access elevation data from the SRTM (Shuttle \n",
    "Radar Topography Mission) via an internet web interface. The \n",
    "earthaccess API bascially makes a request to this data repository \n",
    "and returns requested data per parameters given, in this case \n",
    "parameters will be set in order to access a subset of data for elevation.\n",
    "The SRTM data is data that has \"been enhanced to fill areas of missing data \n",
    "(Void Filled) to provide more complete digital elevation data\", otherwise \n",
    "there would be missing tiles in the data. This data is available at \n",
    "a 30 meter (1 arc second) resolution which is the same as the POLARIS \n",
    "data which is important. While there are a few data formats and file \n",
    "formats of the SRTM available, for this project the ____ data format \n",
    "is used, and the ____ file format. These are used because .....\n",
    "\n",
    "SRTM data was collected via a satellite mission on the *Endeavour* in \n",
    "2000 by NASA and NGA (National Geospatial-Intelligence Agency) to collect \n",
    "radar data to create the first near global set of land elevations (Earth \n",
    "Resources Observation and Science (EROS) Center). Because this data comes \n",
    "from authoritative sources it can be trusted to a degree, but will need to \n",
    "keep in mind that the void filled areas while \"using interpolation algorithms \n",
    "in conjunction with other sources of elevation data\", may not be 100% accurate.\n",
    "To learn more about the Shuttle Radar Topography Mission itself, as well as \n",
    "data and file formats of SRTM please vist \n",
    "[USGS EROS Archive - Digital Elevation - Shuttle Radar Topography Mission (SRTM)](https://www.usgs.gov/centers/eros/science/usgs-eros-archive-digital-elevation-shuttle-radar-topography-mission-srtm).\n",
    "\n",
    "The earthaccess API is publically available and the SRTM data is \n",
    "open data as long as proper attribution is given to these sources. \n",
    "To preview the SRTM data visit \n",
    "[Earth Explorer](https://earthexplorer.usgs.gov/) which can help with \n",
    "making sure data is available for a certain area in a certain time frame, \n",
    "etc. to set up parameters wanted when using the earthaccess API. \n",
    "\n",
    "* ### Climate Data: MACAv2 via THREDDS data server (climate scenarios)\n",
    "\n",
    "Climate Projection Models are one way to guide restoration of many habitats \n",
    "in face of climate change. These projection models use outputs of Global \n",
    "Climate Models (GCM), which simulate the global and regional scale climate \n",
    "processes that have data collected from satellites, weather stations, oceanic \n",
    "buoys, and other methods. As part of the Climate Model Intercomparison Project \n",
    "phase 5 (CMIP5), data was drawn from over 40 GCM's from coutnries across the globe \n",
    "to analyze and compare these many GCM's (Taylor et al., 2012). This comparison \n",
    "allows for better understanding of climate change now/historically as well as \n",
    "in the future. However, one of the drawbacks of this being global data is that \n",
    "it has coarse resolution because of the scale, so an image or map using the data \n",
    "would appear like a pixelated photo of low resolution.\n",
    "\n",
    "One way to try to combat this coarse resolution is to downscale this spatial data. \n",
    "MACA V2 (Multivariate Adaptive Constructed Analogs, version 2) does just that \n",
    "(Abatzoglou and Brown, 2012). Using statistical operations \n",
    "([find more information here](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/joc.2312))\n",
    ", that result in a 4km resolution which produces a higher resolution image.\n",
    "It should be noted that MACA V2 is only for CONUS, a similar type of dataset \n",
    "may heve been done in other regions globally but that would need to be researched \n",
    "further if interested in a project location outside CONUS. This higher \n",
    "resolution will complement the other raster data being used in this project \n",
    "which is at a 30 meter resolution (POLARIS and SRTM). While 4km and 30m are \n",
    "upon face value are vastly different numbers, climate data represents broader\n",
    "atmospheric conditions across a larger area, while the soil data is at a 30m \n",
    "resolution due to the much higher variability in soil properties and elevation \n",
    "across smaller distances, making finer detail necessary to accurately \n",
    "capture local soil characteristics and elevation. Essentially, climate is more \n",
    "uniform over larger areas compared to soil and elevation which can change \n",
    "significantly within a short distance. \n",
    "\n",
    "While there are benefits to downsizing, a disadvantage to it is that \n",
    "due to the statistical methods used, introduces uncertainty. This needs to be kept \n",
    "in mind, but the MACA V2 dataset is widely accepted by many institutions and \n",
    "organizations such as the U.S. Forest Service.  \n",
    "\n",
    "The THREDDS (Thematic Real-time Environmental Distributed Data Services) data \n",
    "server is a web server that can be used to access the MACA v2 dataset as well \n",
    "as other scientific datasets (Unidata, UCAR). This catalog of datasets, accepts \n",
    "a few different data formats including NetCDF, GRIB, and HDF. Because the \n",
    "data in the MACA V2 dataset is available in NetCDF as its original format, \n",
    "that will work for this project. The MACA V2 is also available as tabular \n",
    "data and GeoTIFF. \n",
    "\n",
    "MACA V2 has 20 different climate models, each of these models can be found \n",
    "[here](https://climate.northwestknowledge.net/MACA/GCMs.php). Each of these \n",
    "has 9 climate variables to choose from, the climate variable options can be \n",
    "found [here](https://climate.northwestknowledge.net/MACA/MACAproducts.php). \n",
    "There are 3 climate scenarios available: actual/historic, intermediate, and worst \n",
    "case climate scenarios. Climate scenarios avilable here are either different \n",
    "time periods or different emissions scenarios. For this project, the climate \n",
    "model CCSM4 is chosen, then climate variable chosen is percipitation and the \n",
    "two temporal climate scenarios will be used. Two different time periods are \n",
    "chosen (actual/ historic - 'historical , and worst case scenario - rcm85), \n",
    "and this route was chosen because it will aid in the analysis of suitable habitats \n",
    "for the Rocky Mountatin Juniper in both of the study areas chosen (Comanche and \n",
    "Pawnee National Grasslands). Different time periods provide insight into the past \n",
    "as well as possible future scenarios and the two can be compared to look at the \n",
    "validity of the habitat suitability model to be created for this project (this will \n",
    "be further discussed in the next section). The MACA data can be downloaded as daily \n",
    "or monthly, and for the purposes of this project, monthly will suffice, the amount \n",
    "of data the daily dataset would have, is not necessary here. \n",
    "\n",
    "The MACA V2 data is available under a \n",
    "[Creative Commons CC0 1.0 Universal dedication license](https://creativecommons.org/publicdomain/zero/1.0/) - \n",
    "the dataset was \"created with funding from the US government \n",
    "and are in the public domain in the United States\" ()\n",
    "This data server can be accessed \n",
    "[here](https://climate.northwestknowledge.net/NWTOOLBOX/mapping.php),\n",
    "but there are many ways the data can be downloaded, please see \n",
    "[MACA website](https://climate.northwestknowledge.net/MACA/gallery_data.php).\n",
    "\n",
    "### Citations:\n",
    "* USDA U.S. Forest Service - Geospatial Data Discovery,\n",
    "[U.S. National Grassland Units](https://data-usfs.hub.arcgis.com/datasets/usfs::national-grassland-units-feature-layer/explore?location=39.118879%2C-104.194688%2C7.05). \n",
    "Published April 14, 2017. Last Update August 26, 2022.\n",
    "\n",
    "* Dr. Chaney, Nathaniel. *POLARIS – a probabilistic soil classification* \n",
    "*and property database over the contiguous United States at a 30-meter*\n",
    "*spatial resolution*. Duke Translation and Commercialization - Available \n",
    "Technoligies.\n",
    "(https://otc.duke.edu/technologies/polaris-a-probabilistic-soil-classification-and-property-database-over-the-contiguous-united-states-at-a-30-meter-spatial-resolution/#:~:text=The%20POLARIS%20soil%20series%20database,of%20the%20currently%20available%20database.)\n",
    "\n",
    "* *Polaris 30m Probabilistic Soil Properties US*. \n",
    "awesome-gee-community-catalog. \n",
    "(https://gee-community-catalog.org/projects/polaris/#data-characteristics).\n",
    "\n",
    "* Chaney, Nathaniel W., Budiman Minasny, Jonathan D. Herman, Travis W. Nauman, \n",
    "Colby W. Brungard, Cristine LS Morgan Alexander B. McBratney, Eric F. Wood, \n",
    "and Yohannes Yimam. \"POLARIS soil properties: 30‐m probabilistic maps of soil \n",
    "properties over the contiguous United States.\" Water Resources Research 55, \n",
    "no. 4 (2019): 2916-2938.\n",
    "\n",
    "* POLARIS soil properties database. \n",
    "(http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/).\n",
    "\n",
    "* *earthaccess API (description in User Guide)*. List of contributors available \n",
    "on [Github](https://github.com/nsidc/earthaccess/?tab=readme-ov-file#contributors).\n",
    "Accessed December 2, 2024. \n",
    "(https://earthaccess.readthedocs.io/en/latest/user-reference/api/api/).\n",
    "\n",
    "* Earth Resources Observation and Science (EROS) Center. \n",
    "*USGS EROS Archive - Digital Elevation - Shuttle Radar Topography Mission (SRTM)*. \n",
    "June 29, 2018.\n",
    "(https://www.usgs.gov/centers/eros/science/usgs-eros-archive-digital-elevation-shuttle-radar-topography-mission-srtm).\n",
    "\n",
    "* *Earth Explorer*. USGS. (https://earthexplorer.usgs.gov/).\n",
    "\n",
    "* Taylor, K.E., R.J. Stouffer, G.A. Meehl: An Overview of CMIP5 and \n",
    "the experiment design. MS-D-11-00094.1, 2012.\n",
    "\n",
    "* Abatzoglou J.T. and Brown T.J. (2012). \"A comparison of statistical \n",
    "downscaling methods suited for wildfire applications\". International \n",
    "Journal of Climatology, \n",
    "[doi: 10.1002/joc.2312](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/joc.2312). \n",
    "Funding agencies: Regional Approaches to Climate Change (REACCH), the Climate \n",
    "Impacts Research Consortium(CIRC) and the Northwest/SouthEast Climate Science \n",
    "Centers(NWCSC,SECSC).\n",
    "\n",
    "* Portier, Andrea, (NASA GSFC / SSAI). *Shedding Light on the Future of* \n",
    "*Earth's Climate with NASA Data*. August 24, 2021. (https://gpm.nasa.gov/applications/shedding-light-future-earths-climate-nasa-data#:~:text=%E2%80%9CNASA%20is%20a%20leader%20in,decisions%20that%20directly%20impact%20society).\n",
    "\n",
    "* Unidata, UCAR. *THREDDS Data Server version 4.6 Documentation - THREDDS Data* \n",
    "*Server 4.6*. Updated November 2018. \n",
    "(https://docs.unidata.ucar.edu/tds/4.6/adminguide/#:~:text=The%20THREDDS%20Data%20Server%20(TDS,other%20remote%20data%20access%20protocols).\n",
    "\n",
    "* MACA website - \"CMIP5 GCMs\" (list). (https://climate.northwestknowledge.net/MACA/GCMs.php).\n",
    "\n",
    "* MACA website - \"MACA Downscaled Variables\". (https://climate.northwestknowledge.net/MACA/MACAproducts.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methods Description**\n",
    "\n",
    "With the goal of building a habitat suitability model, there are \n",
    "many steps that need to happen prior to being able to do that.\n",
    "\n",
    "1. **Define study area(s):** Download the \n",
    "[USFS National Grassland Units](https://data-usfs.hub.arcgis.com/datasets/usfs::national-grassland-units-feature-layer/explore?location=39.118879%2C-104.194688%2C7.05) \n",
    "and select 1 or more grassland units.\n",
    "\n",
    "    - I chose Comanche and Pawnee Nation Grasslands as study sites. \n",
    "    The USFS National Grassland Units are 'administrative boundaries' \n",
    "    and this data is used to bound and crop the 3 sets of raster data \n",
    "    being used in this project as well as provide boundaries when plots \n",
    "    are created.\n",
    "\n",
    "2. **Fit a model:** \n",
    "\n",
    "    a. For each grassland, download model variables as raster \n",
    "    layers covering the study area envelope, including:\n",
    "\n",
    "    i. 1 soil variable from the \n",
    "    [POLARIS dataset](http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/) \n",
    "    \n",
    "    - I chose pH. Using this \n",
    "    raster data will provide insight into this soil property in the \n",
    "    study areas chosen.\n",
    "\n",
    "    ii. Elevation from the [SRTM](https://earthexplorer.usgs.gov/) \n",
    "    (use the \n",
    "    [earthaccess API](https://earthaccess.readthedocs.io/en/latest/user-reference/api/api/))\n",
    "\n",
    "    - This will be used to calculate slope later. For the Rocky Mountain \n",
    "    Juniper, they are frequently located in ravines, canyons, and \n",
    "    rocky barrens, so they woulc be located in areas with steep slopes,\n",
    "    or where are are drastic differences in slope.\n",
    "\n",
    "    - **Calculate at least one derived topographic variable (slope or aspect)** \n",
    "    to use in the model. Use the xarray-spatial library, and update or install this \n",
    "    library if not already on machine being used. Note that calculated slope may \n",
    "    not be correct if using a CRS with units of degrees; need to re-project into \n",
    "    a projected coordinate system with units of meters, such as the appropriate \n",
    "    UTM Zone. \n",
    "\n",
    "    - I am choosing slope for this project because it more closely relates to \n",
    "    where the Rocky Mountain Juniper is found in the Comanche and Pawnee National \n",
    "    Grasslands. It is found in ravines, canyons, and rocky barrens, so the slope \n",
    "    would possibly provide more information in the habitat suitablity model.\n",
    "        \n",
    "    iii. Climate variables from the \n",
    "    [MACAv2](https://climate.northwestknowledge.net/MACA/index.php) [THREDDS](https://docs.unidata.ucar.edu/tds/4.6/adminguide/#:~:text=The%20THREDDS%20Data%20Server%20(TDS,other%20remote%20data%20access%20protocols)) \n",
    "    data server. This project will use 16 climate scenarios \n",
    "    of choice (e.g. different time periods, different emission \n",
    "    scenarios).\n",
    "\n",
    "    - **Time Periods Chosen**\n",
    "\n",
    "        - Two different time periods are chosen *'historical' (1970-1999)* and \n",
    "        *late 21st century* (2071-2099). These specific years match up with the \n",
    "        individual file start and end years of the MACAv2 data. This route was chosen \n",
    "        because it will aid in the analysis of suitable habitats for the Rocky \n",
    "        Mountatin Juniper in both of the study areas chosen (Comanche and Pawnee \n",
    "        National Grasslands) that are roughly 100 years apart. Different time periods \n",
    "        provide insight into the past as well as possible future scenarios and the \n",
    "        two can be compared to look at the validity of the habitat suitability model \n",
    "        to be created for this project. Also, because the  detailed research sources \n",
    "        I found were from 1998 and 2004, those years fall within the 'historical' time \n",
    "        frame and the research can also be used to validate the habitat suitability \n",
    "        model regarding the 'historical' time period (Hazlett 1998 and 2004). The \n",
    "        MACA data can be downloaded as daily or monthly, and for the purposes of \n",
    "        this project, monthly will suffice, the amount of data the daily dataset \n",
    "        would have, is not necessary here. \n",
    "\n",
    "    - **Climate Models Chosen: Reasoning**\n",
    "        - Constant variables/scenarios of - RCP 8.5 as the Emission Scenario, \n",
    "        Climate Variables of precipitation and temperature minimum (°F). \n",
    "        The RCP8.5 Emission Scenario was chosen because that is the worst \n",
    "        case scenario for emissions and given that these two grasslands are \n",
    "        geographically close, I am interested in the most extreme emissions \n",
    "        scenario to see if that helps with the habitat model picking up on \n",
    "        differences that could be compared in the two grasslands. Those climate \n",
    "        varibales were chosen because that is information I could find about \n",
    "        the Rocky Mountain Juniper's growth conditions. In theory, if available, \n",
    "        I would be interested in the temperature max it can tolerate as well, \n",
    "        but that couldn't be found given the research sources I am using.\n",
    "\n",
    "        - Using the Future Climate Scatter from the Climate Toolbox I chose 4\n",
    "        climate models for each time period that was previously decided upon \n",
    "        (University of California MERCED n.d., \"Climate Toolbox\").\n",
    "        Within each time period what I am trying to do is pick climate models \n",
    "        where the two warm scenarios are close in temperature, the two cold's \n",
    "        are close in temperature, the precipitation for dry is close, the \n",
    "        precipitation for wet is close. The goal of that is to have as little \n",
    "        variation within the time period, so more can hopefully be explained \n",
    "        by the climate model rather than the variation in the temp or precipitation.\n",
    "        A full list of the specific climate models are available\n",
    "        [here](https://climate.northwestknowledge.net/MACA/GCMs.php), and this \n",
    "        website also provides information on how the climate models are downscaled \n",
    "        for better resolution (University of California MERCED. n.d. \n",
    "        “CMIP5 GCMs and MACA Statistical Downscaling Method.)\n",
    "\n",
    "    #### **Climate Models for the Comanche National Grassland**\n",
    "\n",
    "     **Time Period - 2071-2099**\n",
    "    -   Warm and wet: CanESM-2 - 8.9in precipitation,  28.6(°F) temp min\n",
    "    -   Warm and dry: IPSL-CM5A-MR - 3.3in precipitation, 29 (°F) temp min\n",
    "    -   Cold and wet: MRI-CGCM3 - 8.4in precipitation,  23.5(°F) temp min\n",
    "    -   Cold and dry: bcc-csm1-1-m - 4.8in precipitation,  25.4(°F) temp min\n",
    "\n",
    "     **Time Period - Historical 1970-1999**\n",
    "    -   Warm and wet: CanESM2 - 7.9in precipitation, 19(°F) temp min\n",
    "    -   Warm and dry: CCSM4 - 7.0in precipitation, 18.9(°F) temp min\n",
    "    -   Cold and wet: HadGEM2-CC365 - 7.5in precipitation, 18.2(°F) temp min\n",
    "    -   Cold and dry: inmcm4- 6.4in precipitation, 18.6(°F) temp min\n",
    "\n",
    "    #### **Climate Models for the Pawnee National Grassland**\n",
    "\n",
    "     **Time Period - 2071-2099**\n",
    "    -   Warm and wet: CanESM2 - 6.8in precipitation, 26.8(°F) temp min\n",
    "    -   Warm and dry: HadGEM2-CC365 - 3.6in precipitation,  27.9(°F) temp min\n",
    "    -   Cold and wet: GFDL-ESM2G - 7.2in precipitation, 21.9(°F) temp min\n",
    "    -   Cold and dry: CSIRO-Mk3-6-0 - 4.2in precipitation, 22.5(°F) temp min\n",
    "\n",
    "     **Time Period - Historical 1970-1999** \n",
    "    -   Warm and wet: BNU-ESM - 6.7in precipitation, 15.5(°F) temp min\n",
    "    -   Warm and dry: bcc-csm1-1-m - 6.1in precipitation, 15.4(°F) temp min\n",
    "    -   Cold and wet: IPSL-CM5A-MR - 6.9in precipitation,  14.9(°F) temp min\n",
    "    -   Cold and dry: bcc-csm1-1 - 6.1in precipitation,  14.8(°F) temp min\n",
    "\n",
    "    b. **Harmonize data** - make sure that the grids for each of the layers \n",
    "    match up. Check out the ds.rio.reproject_match() method from rioxarray.\n",
    "\n",
    "    - This step is very important. The model cannot be built if the different \n",
    "    layers are off or on different grids; they have to relate to one another \n",
    "    in order to do the raster math in the next step. The data will be harmonized \n",
    "    to the lowest resolution raster of the group, higher resolution can be made \n",
    "    into a lower resolution, but not vice versa. Although this may sound bad, \n",
    "    most of the rasters chosen are around 1x1 degrees so there should in theory \n",
    "    not be a huge depreciation in resolution.\n",
    "\n",
    "3. **Build habitat suitability model** - use any model, so long as the choice of model \n",
    "is explained. However, if it is not clear how to proceed, building a fuzzy \n",
    "logic model (see below) is best. I will be doing a fuzzy logic model.\n",
    "\n",
    "- To train a fuzzy logic habitat suitability model:\n",
    "\n",
    "    - Use research done on the plant species chosen (Rocky Mountain Juniper), \n",
    "    and find the optimal values for each variable being used \n",
    "    (e.g. soil pH (5-8.5), slope (5,000-7,500ft elevation), and current \n",
    "    climatological annual precipitation (9 inches - 26 inches, 228.6 - 660.4 mm).\n",
    "    For each digital number in each raster, assign a value from 0 to 1 for \n",
    "    how close that grid square is to the optimum range (1=optimal, 0=incompatible). \n",
    "    Combine raster layers by multiplying them together \n",
    "    ([raster math](https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/subtract-rasters-in-python/)). \n",
    "    This will output a single suitability number for each square. \n",
    "    Another option would be to apply a  threshold to make the most \n",
    "    suitable areas pop on the map created.\n",
    "\n",
    "4. **Present the results of the model** in at least one figure for each \n",
    "grassland/climate scenario combination.\n",
    "\n",
    "    - The output raster from the fuzzy logic habitat suitability model \n",
    "    will be used with the overlay of the boundaries of the study area.\n",
    "    Multiple plots will be made to account for each grassland/climate 'scenario, \n",
    "    so there should be 4 plots to finish the concluding thoughts.\n",
    "\n",
    "### Citations\n",
    "\n",
    "* Hazlett, Donald. 1998. “Vascular Plant Species of the Pawnee National \n",
    "Grassland.” U.S. Department of Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr017.pdf.\n",
    "\n",
    "* Hazlett, Donald L. 2004. “Vascular Plant Species of the Comanche \n",
    "National Grassland in Southeastern Colorado.” U.S. Department of \n",
    "Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr130.pdf.\n",
    "\n",
    "* University of California MERCED. n.d. “CMIP5 GCMs and MACA Statistical \n",
    "Downscaling Method.” Northwestknowledge.net. University of California \n",
    "MERCED. Accessed March 1, 2025. \n",
    "https://climate.northwestknowledge.net/MACA/GCMs.php.\n",
    "\n",
    "* University of California MERCED. n.d. “Climate Toolbox: Future Climate \n",
    "Scatter.” Climatetoolbox.org. University of California MERCED. Accessed \n",
    "March 1, 2025. https://climatetoolbox.org/tool/Future-Climate-Scatter.\n",
    "\n",
    "* Wasser, Leah, Chris Holdgraf, Martha Morrissey. \n",
    "The Intermediate earth data science textbook course: *Lesson 2. Subtract* \n",
    "\"One Raster from Another and Export a New GeoTIFF in Open Source Python.\"\n",
    "(https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/subtract-rasters-in-python/).\n",
    "DOI: https://doi.org/10.5281/zenodo.4683910. License: CC BY-SA 4.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.4/dist/panel.min.js\", \"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.13.1/dist/geoviews.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='29351769-00a8-44e5-8d4f-e7454f3eb0ed'>\n",
       "  <div id=\"dbd33638-d737-45cc-bb61-965aeef20958\" data-root-id=\"29351769-00a8-44e5-8d4f-e7454f3eb0ed\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"8fe8c3ab-cebc-4c86-a176-c2aa04664aec\":{\"version\":\"3.5.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"29351769-00a8-44e5-8d4f-e7454f3eb0ed\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"c403f2e8-52af-4a08-b438-34196e3a9293\",\"attributes\":{\"plot_id\":\"29351769-00a8-44e5-8d4f-e7454f3eb0ed\",\"comm_id\":\"e8f09283287c4c22a76cd4d2f2d98f89\",\"client_comm_id\":\"1376517b92984ccc8eb942bc0ed20c24\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"8fe8c3ab-cebc-4c86-a176-c2aa04664aec\",\"roots\":{\"29351769-00a8-44e5-8d4f-e7454f3eb0ed\":\"dbd33638-d737-45cc-bb61-965aeef20958\"},\"root_ids\":[\"29351769-00a8-44e5-8d4f-e7454f3eb0ed\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "29351769-00a8-44e5-8d4f-e7454f3eb0ed"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.13.1/dist/geoviews.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set Up Analysis Part 1 of 2\n",
    "\n",
    "## Import packages that will help with...\n",
    "\n",
    "# Reproducible file paths\n",
    "import os # Reproducible file paths and basic formatting\n",
    "from glob import glob  # returns list of paths\n",
    "import pathlib # Find the home folder\n",
    "import time # formatting time\n",
    "import warnings # Filter warning messages\n",
    "import zipfile # Work with zip files\n",
    "\n",
    "# Work with tabular, vector, and raster data\n",
    "import cartopy.crs as ccrs # CRSs (Coordinate Reference Systems)\n",
    "import earthaccess # Access NASA data from the cloud\n",
    "import geopandas as gpd # work with vector data\n",
    "import geoviews as gv # holoviews extension for data visualization\n",
    "import holoviews as hv # be able to save hvplots\n",
    "import hvplot.pandas # Interactive tabular and vector data\n",
    "import hvplot.xarray # Interactive raster\n",
    "from math import floor, ceil # working with bounds, floor rounds down ciel rounds up\n",
    "import matplotlib.pyplot as plt # Overlay pandas and xarry plots, Overlay raster and vector data\n",
    "import numpy as np # numerical computing\n",
    "import pandas as pd # Group and aggregate\n",
    "import rioxarray as rxr # Work with geospatial raster data\n",
    "from rioxarray.merge import merge_arrays # Merge rasters\n",
    "import xarray as xr # Adjust images\n",
    "import xrspatial # calculate slope\n",
    "\n",
    "# import to visualize progress of iterative operations\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "# Suppress third party warnings - 'ignore'\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Analysis Part 2 of 2\n",
    "\n",
    "# Define and create the project data directory\n",
    "rmj_hab_suit_data_dir = os.path.join(\n",
    "    pathlib.Path.home(),\n",
    "    'earth-analytics',\n",
    "    'data',\n",
    "    'rmj_habitat_suitability'\n",
    ")\n",
    "os.makedirs(rmj_hab_suit_data_dir, exist_ok=True)\n",
    "\n",
    "# Call the data directory to check its location\n",
    "rmj_hab_suit_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Study Areas - USFS National Grassland Units\n",
    "## (Comanche and Pawnee National Grasslands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site Boundary Data (Comanche and Pawnee National Grasslands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download USFS National Grasslands Units Data Part 1 of 1\n",
    "\n",
    "# Define info for USFS National Forests download\n",
    "usfs_grasslands_url = (\n",
    "    \"https://data.fs.usda.gov/geodata/edw/\"\n",
    "    \"edw_resources/shp/S_USA.NationalGrassland.zip\"\n",
    ")\n",
    "# Create directory and path for grassland data\n",
    "usfs_grasslands_dir = os.path.join(\n",
    "    rmj_hab_suit_data_dir, 'usfs_grasslands')\n",
    "os.makedirs(usfs_grasslands_dir, exist_ok=True)\n",
    "usfs_grasslands_path = os.path.join(\n",
    "    usfs_grasslands_dir, 'usfs_grasslands.shp')\n",
    "\n",
    "# Only download once - conditional\n",
    "if not os.path.exists(usfs_grasslands_path):\n",
    "    usfs_grasslands_gdf = gpd.read_file(usfs_grasslands_url)\n",
    "    usfs_grasslands_gdf.to_file(usfs_grasslands_path)\n",
    "\n",
    "# Load from file\n",
    "usfs_grasslands_gdf = gpd.read_file(usfs_grasslands_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Each Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots of each study area, Part 1 of 2\n",
    "\n",
    "# Create new variable for comanche gdf / select data from Comanche National Grassland\n",
    "comanche_grassland_gdf = (\n",
    "    # Pull comanche through the grassland name column\n",
    "    usfs_grasslands_gdf[usfs_grasslands_gdf.GRASSLANDN=='Comanche National Grassland']\n",
    ")\n",
    "# Create new variable for plot in order to save it later\n",
    "comanche_grassland_site_map = (\n",
    " # Create an interactive site map using hvplot \n",
    " comanche_grassland_gdf.hvplot(\n",
    "     geo=True,\n",
    "     tiles='EsriImagery',\n",
    "     title='Comanche National Grassland - Site Map',\n",
    "     fill_color='lightblue', line_color='blue', line_width=2.5,\n",
    "     width=600, height=400\n",
    " )\n",
    ")\n",
    "\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(comanche_grassland_site_map, 'comanche_grassland_site_map.html') \n",
    "# Display the plot \n",
    "comanche_grassland_site_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comanche National Grassland has discontinuous boundaries - this reflects\n",
    "## how the grasslands were purchased\n",
    "\n",
    "The Comanche National Grassland has discontinuous boundaries. \n",
    "This reflects how the land was purchased by the federal U.S. government \n",
    "as parcels or groups of parcels (Worster 2004). A parcel is an area with \n",
    "a distinct boundary and a unique identifier; they are drawn as polygons \n",
    "and are often rectangles or squares unless defined by a natural boundary \n",
    "like a river or lake. Parcels can be arbitrary or of different sizes, \n",
    "; parcels can be combined or divded into new parcels per local regulations. \n",
    "Due to the variable nature of what can be done with the administrative \n",
    "boundary of a parcel, is why there are so many separated parcels in the \n",
    "grassland of different sizes and shapes. The USFS may not own the land \n",
    "surrounding or in between these boundaries. The habitat suitability model \n",
    "being built for this project may be applied on a very broad level to the \n",
    "surrounding areas; however, the habitat suitability model is only pertaining \n",
    "to land within these administrative boundaries. While the administrative \n",
    "boundaries may seem somewhat arbitrary, the findings of the habitat suitability \n",
    "model can help guide decisions made about the grassland itself, which the \n",
    "USFS owns and makes decisons on (sometimes in conjunction with other agencies\n",
    "or entities).\n",
    "\n",
    "The Comanche National Grassland is separated in two areas or units. One unit, \n",
    "the Timpas Unit, is slightly north of the Carrizo Unit (Hazlett 2004). This \n",
    "National Grassland has a range of longitude of -104.2 through 102.2. \n",
    "\n",
    "This information will lay the ground for further layers and the habitat \n",
    "suitabaility model later.\n",
    "\n",
    "### Citations:\n",
    "\n",
    "* Hazlett, Donald L. 2004. “Vascular Plant Species of the Comanche \n",
    "National Grassland in Southeastern Colorado.” U.S. Department of \n",
    "Agriculture, U.S. Forest Service. \n",
    "https://www.fs.usda.gov/rm/pubs/rmrs_gtr130.pdf.\n",
    "\n",
    "* Worster, Donald. 2004. Dust Bowl : The Southern Plains in the 1930s. \n",
    "25th Anniversary Edition. New York: Oxford University Press.\n",
    "(https://global.oup.com/ushe/product/dust-bowl-9780195174885?cc=us&lang=en&)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots of each study area, Part 2 of 2\n",
    "\n",
    "# Create an interactive site map, select data from Pawnee National Grassland\n",
    "pawnee_grassland_gdf = (\n",
    "    # Pull pawnee through the grassland name column\n",
    "    usfs_grasslands_gdf[usfs_grasslands_gdf.GRASSLANDN=='Pawnee National Grassland']\n",
    ")\n",
    "# Create new variable for plot in order to save it later\n",
    "pawnee_grassland_site_map = (\n",
    "    # Create an interactive site map using hvplot \n",
    "    pawnee_grassland_gdf.hvplot(\n",
    "        geo=True, \n",
    "        tiles='EsriImagery',\n",
    "        title='Pawnee National Grassland - Site Map',\n",
    "        fill_color='lightblue', line_color='blue', line_width=2,\n",
    "        width=700, height=400\n",
    "    )\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(pawnee_grassland_site_map, 'pawnee_grassland_site_map.html') \n",
    "\n",
    "# Display the plot \n",
    "pawnee_grassland_site_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pawnee National Grassland has discontinuous boundaries - this reflects\n",
    "## how the grasslands were purchased\n",
    "\n",
    "Similar to the Comanche National Grassland, the Pawnee National Grassland\n",
    "also has discontinuous boundaries. This reflects how the land was purchased \n",
    "by the federal U.S. government as parcels or groups of parcels (parcels \n",
    "are described in the above description for the Comanche National Grassland) \n",
    "(Worster 2004). The USFS may not own the land surrounding or in between \n",
    "these boundaries. While the habitat suitability model being built for this \n",
    "project may be applied on a very broad level to the surrounding areas, the \n",
    "habitat suitability model is only pertaining to land within these administrative \n",
    "boundaries.While the administrative boundaries may seem somewhat arbitrary, \n",
    "the findings of the habitat suitability model can help guide decisions made \n",
    "about the grassland itself, which the USFS owns and makes decisons on (sometimes \n",
    "in conjunction with other agencies).\n",
    "\n",
    "The Pawnee National Grassland is also separated in two areas. The difference \n",
    "with these is that both areas are somewhat paralell to each other, with the \n",
    "right one extending slightly more north. It has similar range of longitude \n",
    "to the Comanche National Grassland, Pawnee's is -104.9 through -103.4 and \n",
    "Comanche's is -104.2 through 102.2. However Pawnee National Grassland is \n",
    "roughly 2 degrees latitude further north than Comanche. Both grasslands \n",
    "chosen span roughly 1 degree in latitude.\n",
    "\n",
    "This information will lay the ground for further layers and the habitat \n",
    "suitabaility model later.\n",
    "\n",
    "### Citations:\n",
    "\n",
    "* Worster, Donald. 2004. Dust Bowl : The Southern Plains in the 1930s. \n",
    "25th Anniversary Edition. New York: Oxford University Press.\n",
    "(https://global.oup.com/ushe/product/dust-bowl-9780195174885?cc=us&lang=en&)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrangle the Raster Data (3 layers)\n",
    "# Part 1: POLARIS dataset - download 1 soil variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process POLARIS Raster Image Part 1 of 2\n",
    "\n",
    "# Create function with description to process raster images\n",
    "def process_image(url, soil_prop, soil_stat, soil_depth, bounds_gdf):\n",
    "    \"\"\"\n",
    "    Load, crop, and scale raster images for multiple sites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: str\n",
    "      URL or path for raster files.\n",
    "    soil_prop: str\n",
    "      Soil property (e.g., \"sand\", \"clay\", etc.)\n",
    "    soil_stat: str\n",
    "      Soil statistic (e.g., \"mean\", \"median\", etc.)\n",
    "    soil_depth: str\n",
    "      Soil depth (e.g., \"30-60cm\", \"60-100cm\", etc.)\n",
    "    bounds_gdf: gpd.GeoDataFrame\n",
    "      Area of interest to crop to.\n",
    "    site_names: list\n",
    "      List of site names to be used as dictionary keys.\n",
    "    Returns\n",
    "    -------\n",
    "   merged_da: rxr.DataArray\n",
    "      Processed rasters \n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through the list of bounding GeoDataFrames (areas of interest)\n",
    "    #for site_name, bounds_gdf in zip(site_names, bounds_gdfs):\n",
    "\n",
    "    # Get the study bounds\n",
    "    bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "    bounds_gdf\n",
    "    .to_crs(4326)\n",
    "    .total_bounds \n",
    "    )\n",
    "\n",
    "    # List to store cropped DataArrays for the current site\n",
    "    da_list = []\n",
    "    \n",
    "    # Loop through bounding box coordinates\n",
    "    for min_lon in range(floor(bounds_min_lon), ceil(bounds_max_lon)):\n",
    "      for min_lat in range(floor(bounds_min_lat), ceil(bounds_max_lat)):\n",
    "\n",
    "        # Format the URL with the current coordinates and other parameters\n",
    "        formated_url = (\n",
    "          url.format( \n",
    "              soil_prop = soil_prop, \n",
    "              soil_stat = soil_stat, \n",
    "              soil_depth = soil_depth,\n",
    "              min_lat=min_lat , max_lat=min_lat+1,\n",
    "              min_lon=min_lon, max_lon=min_lon+1 )\n",
    "        )\n",
    "\n",
    "        # Connect to the raster image\n",
    "        da = rxr.open_rasterio(\n",
    "        formated_url, \n",
    "        mask_and_scale=True\n",
    "        ).squeeze()\n",
    "        \n",
    "        # Crop the raster image to the bounds of the study area\n",
    "        cropped_da = (\n",
    "        da.rio.clip_box(bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat)\n",
    "        )\n",
    "\n",
    "        # Append the cropped DataArray to the list\n",
    "        da_list.append(cropped_da)   \n",
    "\n",
    "    # Merge the cropped DataArrays for this site\n",
    "    merged_da = merge_arrays(da_list)\n",
    "\n",
    "    return merged_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process POLARIS raster image part 2 of 2\n",
    "# Test the function by defining variables to pass as arguments to the function\n",
    "\n",
    "# Set the site parameters\n",
    "# soil variables\n",
    "soil_prop = 'ph'\n",
    "soil_stat = 'mean'\n",
    "soil_depth = '60_100'\n",
    "# set up url template\n",
    "soil_url_template = (\n",
    "            \"http://hydrology.cee.duke.edu\"\n",
    "            \"/POLARIS/PROPERTIES/v1.0\"\n",
    "            \"/{soil_prop}\"\n",
    "            \"/{soil_stat}\"\n",
    "            \"/{soil_depth}\"\n",
    "            \"/lat{min_lat}{max_lat}_lon{min_lon}{max_lon}.tif\"\n",
    "            )\n",
    "\n",
    "# output_directory - create data dir for polaris data \n",
    "polaris_dir= os.path.join(rmj_hab_suit_data_dir, 'polaris')\n",
    "os.makedirs(polaris_dir, exist_ok=True)\n",
    "\n",
    "# Call the directory to check the location\n",
    "polaris_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the study areas and corresponding GeoDataFrames to use in for loop\n",
    "study_areas = (\n",
    "    (\"Comanche National Grassland\", comanche_grassland_gdf),\n",
    "    (\"Pawnee National Grassland\", pawnee_grassland_gdf)\n",
    ")    \n",
    "\n",
    "# Create a list to store the processed data for each study area\n",
    "polaris_processed_da_list = []\n",
    "\n",
    "# Loop through each study area and process the image\n",
    "for area_name, area_gdf in study_areas:\n",
    "    processed_data = process_image(\n",
    "        soil_url_template,\n",
    "        soil_prop, soil_stat, soil_depth,\n",
    "        area_gdf\n",
    "    )\n",
    "    polaris_processed_da_list.append(processed_data)\n",
    "\n",
    "# Call the list to make sure it worked/looks right\n",
    "polaris_processed_da_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pawnee to make sure it works/ looks right\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "polaris_processed_da_list[0].plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True,\n",
    "    )\n",
    "comanche_grassland_gdf.to_crs(polaris_processed_da_list[0].rio.crs).boundary.plot(\n",
    "    ax=plt.gca(),\n",
    "    color='white').set(\n",
    "        title='Comanche National Grassland - pH',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"polaris_comanche_plot.png\", dpi=300)\n",
    "\n",
    "# Display the plot        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comanche Grassland - pH - plotted correctly - the slightly acidic soil \n",
    "## areas appear to be outside the grassland visually. Full pH scale plotted \n",
    "## would work for the Rocky Mountain Juniper\n",
    "\n",
    "The lower unit, Carrizo, is mostly in the upper range of the pH scale bar, \n",
    "while the upper unit, Timpas, if in the middle range of the scale bar. This \n",
    "range of pH plotted, is fully within the acceptable range for a Rocky Mountain \n",
    "Juniper. There is a larger range of pH here than with Pawnee. Without adding \n",
    "additional context or other data it is hard to draw further conclusions so \n",
    "other raster sets will be downloaded next to eventually build a habitat \n",
    "suitability model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Pawnee to make sure it works/ looks right\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "polaris_processed_da_list[1].plot(\n",
    "    cbar_kwargs={\"label\": \"pH\"},\n",
    "    robust=True,\n",
    "    )\n",
    "\n",
    "pawnee_grassland_gdf.to_crs(polaris_processed_da_list[1].rio.crs).boundary.plot(\n",
    "    ax=plt.gca(),\n",
    "    color='white').set(\n",
    "        title='Pawnee National Grassland - pH',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"polaris_pawnee_plot.png\", dpi=300)\n",
    "\n",
    "# Display the plot        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pawnee Grassland - pH - plotted correctly - left area of grassland \n",
    "## appears to have slightly lower pH areas \n",
    "\n",
    "While the left area has slightly lower pH on the scale, pH of 7 and 8 is still \n",
    "considered netural to alkaline soil overall and is within the range that would \n",
    "be acceptable to a rocky mountain juniper. There is a full degree of longitude \n",
    "difference between the left and right areas of this grassland, so it makes sense \n",
    "that there is some variability in this range without adding additional context or \n",
    "other data it is hard to draw further conclusions so other raster sets will be \n",
    "downloaded next to eventually build a habitat suitability model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrangle the Raster Data (3 layers)\n",
    "# Part 2:  Elevation Data using SRTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Raster data through earthaccess Part 1 of 1\n",
    "# Create function to login and search earthaccess, then download results\n",
    "\n",
    "def download_earthaccess_data(bounds_gdfs, dir, short_name):\n",
    "    \"\"\"\n",
    "    Download raster data from EarthAccess for the given areas of interest (bounding GeoDataFrames).\n",
    "    \n",
    "    Args:\n",
    "    - chosen_grasslands_bounds_gdfs (list): List of GeoDataFrames defining the areas of interest.\n",
    "    - elevation_dir (str): Directory where the downloaded files will be saved.\n",
    "    - short_name (str): The short name of the dataset to search for (e.g., \"SRTMGL1\").\n",
    "\n",
    "    Returns:\n",
    "     - list: List of unique file paths that match the pattern for downloaded raster files.\n",
    "    \"\"\"\n",
    "    # Login to earthaccess\n",
    "    earthaccess.login(strategy=\"interactive\", persist=True)\n",
    "\n",
    "    # Initialize a list to store the downloaded files\n",
    "    all_files = []\n",
    "\n",
    "    # Iterate through the list of bounding GeoDataFrames (areas of interest)\n",
    "    for bounds_gdf in bounds_gdfs:\n",
    "        \n",
    "        # Set bounds from the GeoDataFrame\n",
    "        bounds = tuple(bounds_gdf.total_bounds)\n",
    "\n",
    "        # Search EarthAccess for SRTM data within the bounds\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=short_name,\n",
    "            bounding_box=bounds\n",
    "        )\n",
    "        \n",
    "        # Download the EarthAccess results\n",
    "        files = earthaccess.download(results, dir)\n",
    "\n",
    "        # Collect all downloaded files that match the pattern\n",
    "        files = glob(os.path.join(dir, '*hgt.zip'))\n",
    "        \n",
    "        # Add the found files to the overall list\n",
    "        all_files.extend(files)\n",
    "\n",
    "    # Remove duplicates while preserving the order\n",
    "    unique_raster_files = []\n",
    "    seen = set()\n",
    "    for file in all_files:\n",
    "            if file not in seen:\n",
    "                unique_raster_files.append(file)\n",
    "                seen.add(file)\n",
    "\n",
    "    return unique_raster_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Raster data through earthaccess Part 1 of 1\n",
    "\n",
    "# Test the function above (download_earthaccess_data)\n",
    "# First define variables to pass as arguments to the function\n",
    "\n",
    "# bounds gdfs\n",
    "chosen_grasslands_bounds_gdfs = [comanche_grassland_gdf, pawnee_grassland_gdf]\n",
    "\n",
    "# Create data dir \n",
    "elevation_dir= os.path.join(rmj_hab_suit_data_dir, 'srtm')\n",
    "os.makedirs(elevation_dir, exist_ok=True)\n",
    "# call the variable to check location\n",
    "elevation_dir\n",
    "\n",
    "# Select and set the short_name of dataset wanted\n",
    "short_name=\"SRTMGL1\"\n",
    "\n",
    "# Test the function\n",
    "srtm_files = download_earthaccess_data(chosen_grasslands_bounds_gdfs, elevation_dir, short_name)\n",
    "\n",
    "# Check the result\n",
    "srtm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group SRTM files by coordinates Part 1 of 2\n",
    "\n",
    "# Create function to group files by boundary \n",
    "\"\"\"The last function resulted in the files for SRTM being downloaded, \n",
    "but they need to be sorted based on the coordinates of the grasslands. \n",
    "I chose to do this as separate function to do things piece by piece. Being \n",
    "new to earth data science it's easier for me to understand these as separate \n",
    "ideas or groups of ideas, plus this lets me see that each step works on its \n",
    "own and I could use these functions separately on a different project or \n",
    "projects\"\"\"\n",
    "\n",
    "def group_files_by_bounds(files, bounds):\n",
    "    \"\"\"\n",
    "    Group the files by the bound areas based on the file coordinates.\n",
    "\n",
    "    Args:\n",
    "    - files (list): List of file paths for the downloaded raster files.\n",
    "    - bounds (dict): Dictionary where the key is the bound name, \n",
    "      and the value is the tuple of (min_lat, max_lat, min_lon, max_lon).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with grassland names as keys and lists of files as values.\n",
    "    \"\"\"\n",
    "    # Initialize the dictionary to store grouped files\n",
    "    grouped_files = {bound: [] for bound in bounds}\n",
    "\n",
    "    # Regex to extract coordinates from the filename (e.g., \"N36W105\" from \"N36W105.SRTMGL1.hgt.zip\")\n",
    "    coord_pattern = re.compile(r'([NS])(\\d{2})([EW])(\\d{3})')\n",
    "\n",
    "    # Iterate through each file and extract the coordinates\n",
    "    for file_path in files:\n",
    "        # Get the filename from the full path\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Use regex to extract coordinates from the filename\n",
    "        match = coord_pattern.search(filename)\n",
    "        if match:\n",
    "            lat_dir, lat_deg, lon_dir, lon_deg = match.groups()\n",
    "            lat = int(lat_deg) * (-1 if lat_dir == 'S' else 1)  # Convert to signed integer for latitude\n",
    "            lon = int(lon_deg) * (-1 if lon_dir == 'W' else 1)  # Convert to signed integer for longitude\n",
    "\n",
    "            # Check which grassland the coordinates belong to\n",
    "            for bound_name, bound_coords in bounds.items():\n",
    "                min_lat, max_lat, min_lon, max_lon = bound_coords\n",
    "                # Check if the coordinates are within the bounds\n",
    "                if min_lat <= lat <= max_lat and min_lon <= lon <= max_lon:\n",
    "                    grouped_files[bound_name].append(file_path)\n",
    "\n",
    "    return grouped_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group SRTM files by coordinates Part 2 of 2\n",
    "# Test the group_files_by_bounds function\n",
    "\n",
    "# Use SRTM files defined in last cell\n",
    "\n",
    "# Define the bounds for each grassland (min_lat, max_lat, min_lon, max_lon)\n",
    "grasslands_bounds = {\n",
    "    'Comanche National Grassland': (35, 37, -106, -103),\n",
    "    'Pawnee National Grassland': (39, 41, -106, -104)\n",
    "}\n",
    "\n",
    "# Group the files by grassland based on the coordinates\n",
    "grouped_srtm_files = group_files_by_bounds(srtm_files, grasslands_bounds)\n",
    "\n",
    "# Check the grouped files\n",
    "grouped_srtm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function with description to process srtm raster images\n",
    "# Part 1 of 2\n",
    "def process_image_list(url_list, chosen_buffer, bounds_gdf):\n",
    "    \"\"\"\n",
    "    Load, crop, and scale a raster image \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: file-like or path-like\n",
    "      File accessor downloaded or obtained \n",
    "    chosen_buffer: float number\n",
    "      Amount of degrees to extend past the bounds of the bounds_gdf \n",
    "    bounds_gdf: gpd.GeoDataFrame\n",
    "      Area of interest to crop to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    merged_da: rxr.DataArray\n",
    "      Processed raster\n",
    "    \"\"\"   \n",
    "        \n",
    "    # List to store cropped DataArrays for the current site \n",
    "    da_list= []\n",
    "      \n",
    "    buffer= chosen_buffer\n",
    "\n",
    "    for url in url_list:\n",
    "\n",
    "        # Connect to the raster image\n",
    "        da = rxr.open_rasterio(\n",
    "          url, \n",
    "          mask_and_scale=True\n",
    "          ).squeeze()\n",
    "        \n",
    "          # Get the study bounds\n",
    "        bounds_min_lon, bounds_min_lat, bounds_max_lon, bounds_max_lat = (\n",
    "          bounds_gdf\n",
    "          .to_crs(da.rio.crs)\n",
    "          .total_bounds \n",
    "          )\n",
    "\n",
    "        # Crop the raster image to the bounds of the study area\n",
    "        cropped_da = (\n",
    "          da.rio.clip_box(bounds_min_lon-buffer, bounds_min_lat-buffer, bounds_max_lon+buffer, bounds_max_lat+buffer)\n",
    "          )\n",
    "        \n",
    "        # Append the cropped DataArray to the list\n",
    "        da_list.append(cropped_da)\n",
    "\n",
    "    # Merge the cropped DataArrays for this site\n",
    "    merged_da = (\n",
    "      merge_arrays(da_list)\n",
    "      )\n",
    "        \n",
    "    return merged_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function with description to process srtm raster images\n",
    "# Part 2 of 2\n",
    "\n",
    "# Use process_image_list function in for loop on grouped_srtm_files\n",
    "\n",
    "# List of the study areas and corresponding GeoDataFrames to use in \n",
    "# for loop use 'study_areas' defined earlier\n",
    "\n",
    "# List to store the srtm results\n",
    "srtm_da_results = []\n",
    "\n",
    "# Loop over each grassland and process the corresponding files\n",
    "for grassland_name, gdf in study_areas:\n",
    "    # Process the SRTM files for the current grassland\n",
    "    result_da = process_image_list(grouped_srtm_files[grassland_name], .025, gdf)\n",
    "    \n",
    "    # Append the result to the list\n",
    "    srtm_da_results.append(result_da)\n",
    "\n",
    "# Call srtm_da_results to check that it worked\n",
    "srtm_da_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the processed raster on Comanche National Grassland\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "srtm_da_results[0].plot(\n",
    "    cbar_kwargs={\"label\": \"Elevation (meters)\"},\n",
    "    robust=True,\n",
    "    cmap='terrain',\n",
    ")\n",
    "# Overlay the boundary of the same study area\n",
    "comanche_grassland_gdf.boundary.plot(ax=plt.gca(),\n",
    "    color='black').set(\n",
    "        title='Comanche National Grassland - Elevation ',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "        xticks=[],\n",
    "        yticks=[] \n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"srtm_comanche_plot.png\", dpi=300)\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comanche Grassland Elevation - plotted correctly, wide range in \n",
    "## elevation is seen, the lower half of this range is not within the \n",
    "## perferred range for Rocky Mountain Juniper\n",
    "\n",
    "The elevation scale (1200-1800 meters), is roughly 4000 - 5900 feet in \n",
    "elevation. The rocky mountain juniper's perferred range is 5000 to \n",
    "7500 feet (1524 meters to 2285 meters), so only the upper half of the \n",
    "elevation color bar scale would be applicapable to the species chosen. \n",
    "The lower right unit, Carrizo, has most of the right half of it visually \n",
    "in the elevations that would not be acceptable, and the upper left unit, \n",
    "Timpas, is mostly in the lower half of the elevation scale. So, it will be \n",
    "interesting in further analysis if this is a limiting factor for \n",
    "habitat suitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the processed raster on Pawnee National Grassland\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "srtm_da_results[1].plot(\n",
    "    cbar_kwargs={\"label\": \"Elevation (meters)\"},\n",
    "    robust=True,\n",
    "    cmap='terrain',\n",
    ")\n",
    "# Overlay the boundary of the same study area\n",
    "pawnee_grassland_gdf.boundary.plot(ax=plt.gca(),\n",
    "    color='black').set(\n",
    "        title='Pawnee National Grassland - Elevation ',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "        xticks=[],\n",
    "        yticks=[] \n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"srtm_pawnee_plot.png\", dpi=300)\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pawnee Grassland Elevation - plotted correctly, smaller range in \n",
    "## elevation is seen comapred to Comanche, most of this \n",
    "## range is within the perferred range for Rocky Mountain Juniper\n",
    "\n",
    "Almost all of the left unity would be in areas that are within the \n",
    "suitable range for the Rocky Mountain Juniper. Part of the right unit \n",
    "(left half) would be in areas that are within the suitable range for \n",
    "the Rocky Mountain Juniper. Overall, visually this grassland, compared \n",
    "to the Comanche has more areas within the suitable range for the species \n",
    "chosen, however based on the context, this grassland has less overall \n",
    "acerage or span in longitude and latitude and is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calculate Slope**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(da_results, epsg_in, epsg_out):\n",
    "    \"\"\"\n",
    "    Calculate the slope for each raster in the provided list of data arrays, \n",
    "    and reproject to the desired output CRS.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    da_results : list\n",
    "        List of xarray DataArrays (like SRTM results).\n",
    "    epsg_in : int\n",
    "        The EPSG code of the input CRS (EPSG:32613).\n",
    "    epsg_out : int\n",
    "        The EPSG code for the desired output CRS (EPSG:4326).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    slope_da_list : list\n",
    "        List of xarray DataArrays, each containing the calculated slope, reprojected to the desired CRS.\n",
    "    \"\"\"\n",
    "    # List to store the slope results\n",
    "    slope_da_list = []\n",
    "\n",
    "    # Iterate through each SRTM data array and calculate slope\n",
    "    for result in da_results:\n",
    "\n",
    "        # Reproject to the input CRS (if it's not already)\n",
    "        proj_da = result.rio.reproject(epsg_in)\n",
    "\n",
    "        # Calculate slope (in UTM projection)\n",
    "        slope_da = xrspatial.slope(proj_da)\n",
    "\n",
    "        # Reproject slope to the desired output CRS (e.g., EPSG:4326)\n",
    "        slope_da_reprojected = slope_da.rio.reproject(epsg_out)\n",
    "\n",
    "        # Append to the result list\n",
    "        slope_da_list.append(slope_da_reprojected)\n",
    "\n",
    "    return slope_da_list\n",
    "\n",
    "# Test function for slope, use 32613 as the input CRS and 4326 as the output CRS\n",
    "slope_results = calculate_slope(srtm_da_results, 32613, 4326)\n",
    "\n",
    "slope_results\n",
    "\n",
    "# Now slope_results contains the calculated slope reprojected to EPSG:4326\n",
    "# this matches the grassland boundaries and the polaris data (and eventually \n",
    "# the climate model rasters as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comanche Test to make sure the slope function worked \n",
    "# by plotting\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plot Comanche\n",
    "slope_results[0].plot(\n",
    "    cbar_kwargs={\"label\": \"Slope (degrees)\"},\n",
    "    cmap='terrain',\n",
    ")\n",
    "# Overlay the boundary of the same study area\n",
    "comanche_grassland_gdf.to_crs(4326).boundary.plot(\n",
    "    ax=plt.gca(),\n",
    "    color='white').set(\n",
    "        title='Comanche National Grassland - Caluclated Slope ',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "        xticks=[],\n",
    "        yticks=[] \n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"slope_comanche_plot.png\", dpi=300)\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comanche Caluculated Slope - plotted correctly, visually \n",
    "## there are some areas of degress slope 10-30 which \n",
    "## would potentially be areas that the Rocky Mountain Juiper is \n",
    "## commonly found \n",
    "\n",
    "They Rocky Mountain Juniper is commonly found in rocky canyons and \n",
    "ravines, there is an assumed slope, without finiding specifc degrees, \n",
    "would be around 30. While there doesn't visually appear to be many \n",
    "areas of slope at 30 degrees, there seems to be some areas between \n",
    "maybe 10 and 30 degrees within the grassland boundaries but due to \n",
    "the outline of  boundary, it's hard to see specifically where these \n",
    "areas might be. The habitat suitability mdoel should help with further \n",
    "conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pawnee Test to make sure the slope function worked \n",
    "# by plotting\n",
    "\n",
    "# Set the figure size (width, height in inches)\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plot Pawnee (reprojected slope)\n",
    "slope_results[1].plot(\n",
    "    cbar_kwargs={\"label\": \"Slope (degrees)\"},\n",
    "    cmap='terrain',\n",
    ")\n",
    "\n",
    "# Overlay the boundary of the same study area\n",
    "pawnee_grassland_gdf.to_crs(4326).boundary.plot(\n",
    "    ax=plt.gca(),\n",
    "    color='white').set(\n",
    "        title='Pawnee National Grassland - Calculated Reprojected Slope',\n",
    "        xlabel='Longitude', \n",
    "        ylabel='Latitude',\n",
    "        xticks=[],\n",
    "        yticks=[]\n",
    "    )\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"slope_pawnee_reprojected_plot.png\", dpi=300)\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pawnee Caluculated Slope - plotted correctly, visually \n",
    "## there are few areas of degress slope 10-30 which \n",
    "## would potentially be areas that the Rocky Mountain Juiper is \n",
    "## commonly found \n",
    "\n",
    "Compared to the Comanche Calculated Slope plot, this one appears \n",
    "to visually have fewer areas that have a slope between 10-30 degrees.\n",
    "Of the areas that have a slope greater than 0 it seems to be between \n",
    "0 and 15 degrees, however it is difficult to draw conclusions visually \n",
    "when the resolution is so high. The habitat suitability model should \n",
    "help with further conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was having issues in the fuzzy logic model and \n",
    "# I think this raster is the problem I want to make \n",
    "# sure they are aligned \n",
    "\n",
    "# Check dimensions of the SRTM and slope results\n",
    "for idx, result in enumerate(srtm_da_results):\n",
    "    print(f\"SRTM result {idx} shape: {result.shape}\")\n",
    "    \n",
    "for idx, result in enumerate(slope_results):\n",
    "    print(f\"Slope result {idx} shape: {result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, they are different and need to be aligned\n",
    "# Align both srtm and slop da's to the first raster\n",
    "aligned_srtm_da = []\n",
    "aligned_slope_results = []\n",
    "\n",
    "# Align the SRTM rasters\n",
    "for srtm in srtm_da_results:\n",
    "    aligned_srtm, _ = xr.align(srtm, srtm_da_results[0], \n",
    "        join='outer')  # Align with first element in the list\n",
    "    aligned_srtm_da.append(aligned_srtm)\n",
    "\n",
    "# Align the slope results\n",
    "for slope in slope_results:\n",
    "    aligned_slope, _ = xr.align(slope, slope_results[0], \n",
    "        join='outer')  # Align with first element in the list\n",
    "    aligned_slope_results.append(aligned_slope)\n",
    "\n",
    "# Call the aligned slope results to make sure I can use that later\n",
    "aligned_slope_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrangle the Raster Data (3 layers)\n",
    "# Part 3: MACA v2 THREDDS - download climate models chosen with a function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
